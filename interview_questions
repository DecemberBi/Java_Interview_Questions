面试总结：
	1、基础 （JavaGuide面试突击版）（二哥的进阶之路https://javabetter.cn/sidebar/sanfene/javathread.html)
		代理机制：区分是字节码是编译时生成还是运行时生成
			https://juejin.cn/post/6844903744954433544
			静态代理：编译时生成
				实现某个接口

			动态代理：运行时生成
				JDK动态代理 - 实现接口的方式，基于Java反射机制实现
					Proxy   InvocationHandler
				CGLIB动态代理 - 继承类的方式，基于ASM机制实现
					Enhancer.setSuperClass 实现继承
					实现 MethodInterceptor接口，用来处理对代理类上所有方法的请求
				对比：
					JDK代码实现简单，不需要引入额外的包，可以平滑实现JDK的升级
					CGLIB无需实现接口，达到代理类无侵入，只操作我们关注的类，其他的类无需关注，高性能

		volatile
			保证内存可见性
				写：直接将变量从工作内存写入到主内存中
				读：直接从主内存中进行读取
			禁止指令重排序
				JVM为了优化代码的执行效率会进行指令重排，如果一个操作不是原子操作就有可能导致出现并发问题
				内存屏障，在代码编译阶段，使用内存屏障阻止指令的重排序

		如何保证线程安全
			synchronized关键字
				无锁 - 偏向锁 - 自旋锁 - 重量级锁
				锁升级的过程主要是减少用户态到核心态的切换，提高锁的效率
				自旋锁使用到了CAS（比较并交换）

			lock锁机制
				ReetrantLock是可重复锁，底层时用AQS实现的

		单例Bean实现，为什么要使用volatile
			private static volatile Singleton instance = null;
		    public static Singleton getInstance() {
		        if (instance == null) {                 // ① 减少锁冲突
		            synchronized (Singleton.class) {    // ② 加锁
		                if (instance == null) {         // ③ 防止锁等待完成后再去执行创建bean
		                    instance = new Singleton(); // ④ 使用volatile防止指令重排序
		                }
		            }
		        }
		        return instance;
		    }
			注意⚠️：要加static关键字
			首先解释volatile关键字的作用
				防止指令重排导致并发问题
				具体是指④发生指令重排时，另外一个线程在①处判断instance不为null导致后续执行时发生异常
			然后从单例Bean懒加载中的作用
				防止指令重排序。
				具体是指创建bean时分三步：1创建内存空间，2初始化bean对象，3将内存指向初始化完成的bean


		四种引用类型
			强引用 StrongReference  new创建的对象，不会被垃圾回收器回收，即使内存不够，直接抛出Error
			软引用 SoftReference    非必要但有用的对象，内存足够的时候不会被回收，内存不够的时候会回收
			弱引用 WeakReference    比软引用更弱，只要被垃圾回收器扫描到就会被回收
			虚引用 PhantomReference 最弱的引用，随时可以被回收

		ThreadLocal
			是什么？
				线程本地变量，每个线程创建一个副本，做到线程隔离，避免并发场景下的线程安全问题。
			为什么要用？
				为了解决并发场景下的线程安全问题。
				加锁也能解决，为什么要用？
					加锁会影响线程并发的性能，导致系统变慢。
					采用空间换时间的方式，就是使用ThreadLocal
			使用案例
				SimpleDateFormat不是线程安全的，多个线程同时使用同一个SimpleDateFormat的时候就会出现并发的问题
				使用ThreadLocal包装一层，然后每次获取一下包装后的get拿到本线程的SimpleDateFormat进行操作就不会出现这个问题了
			原理：
				每个线程内部维护一个ThreadLocalMap
				ThreadLocalMap内部维护了一个Entry数组，Entry是一个对象，key是ThreadLocal对象本身，value是ThreadLocal的泛型对象值
				并发场景下，每个线程操作自己的ThreadLocalMap对象。
			为什么会出现内存泄露？
				不再被使用的entry没有从ThreadLocalMap中清除
				ThreadLocalMap使用ThreadLocal的弱引用作为key，当ThreadLocal变量被手动设置为null，当发生系统GC的时候，
				ThreadLocal就一定会被系统回收，ThreadLocalMap中就会出现key为null的entry，当前线程也不能访问到这个entry，导致内存泄露。
			如何解决？
				使用完ThreadLocal后及时使用remove方法进行清除
				ThreadLocalMap自动清除过期Entry（get、set都会触发）

		面向对象的设计原则：SOLID原则
			S：单一职责原则。一个类只负责一项职责
			O：开闭原则。对扩展开放，对修改关闭。更易于扩展，当添加新功能时，尽量不修改原来的代码，通过添加新的代码实现。
			L：里氏替换原则。父类出现的地方，子类一定可以出现。子类扩展父类的功能时，不应改变父类原有的行为。
			I：接口隔离原则。客户端不应该依赖类，而应该依赖接口，同时客户端也不应该依赖它不需要的接口。
			D：依赖倒置原则。设计时应该依赖接口或者抽象类，而不是实现类。

		集合：
			快速失败和安全失败？
				快速失败：java.util包下的集合类
					并发访问集合的时候，使用modCount和expectedModCount判断是否一致，如果不一致，就说明有其他线程并发写入集合，就可以快速抛出Concurrent Modification Exception
				安全失败：java.util.concurrent包下的集合类
					并发访问集合时，先复制原有集合的内容，在拷贝的集合上进行遍历

			ArrayList线程安全的方法
				使用Vector代替（不推荐，历史遗留）
				使用Collections.synchronizedList包装一下
				使用CopyOnWriteArrayList代替
				外层使用同步机制控制ArrayList的读写

			CopyOnWriteArrayList：线程安全的操作ArrayList的类
				使用读写分离的并发策略。读是无锁的，允许并发读。当发生写操作时，先复制一份数据，然后在复制的副本上进行操作写，写完之后将原来的指针指向新写的副本完成替代。

			hashmap
				结构：数组+链表+红黑树
				线程不安全：
					扩容时：
						会形成循环链表，主要原因是1.7时会有循环链表（头插法）1.8使用尾插法解决
						并发查和写会导致get出来为null
					多线程并发插入到同一个槽时会出现数据覆盖的情况
				如何解决：
					1、直接加锁
					2、使用hashtable，本质还是加锁
					3、使用concurrentHashMap，也是加锁，不过降低了锁的粒度，减小锁的竞争来提高并发度
						1.7 基于segment加reentrantLock
						1.8 基于entry节点使用synchronized
				红黑树的了解：本质上是二叉查找树，在二叉查找树的基础上增加了很多的规则
					1、每个节点要么是红色，要么是黑色
					2、根节点一定是黑色的
					3、叶子节点一定是黑色的
					4、每个红色节点的两个子节点一定是黑色的
					5、从任意一个节点到其子树的每个叶子节点的路径都包含相同数量的黑色节点

					为什么不用二叉树？
						二叉树不是平衡的，可能会退化成链表结构，避免出现O(N)复杂度的情况
					为什么不用平衡二叉树？
						平衡二叉树比红黑树更严格，为了保持平衡会有更多的旋转操作，效率会更低。


		并发编程：
			sleep和wait的区别：
				sleep是让当前线程休眠一段时间，不涉及对象类，也不涉及锁的获取，也不释放锁，是属于Thread类的方法；
				wait是让获得对象锁的线程等待，前提得先获取到对象的锁，wait时会释放锁，是属于Object类的方法。

			线程有几种状态：
				NEW、RUNNABLE、BLOCKED、WAITING、TIME_WAITING、TERMINATED

			什么是双下文切换？
				在RUNNABLE状态，其实对应系统的两个状态：就绪和运行。CPU执行任务的时候是以时间片的方式轮流执行每个线程的任务。
				当一个线程使用完时间片之后，要保存其执行状态，处于就绪状态并让出CPU给其他线程占用，这就是上下文切换。

			线程间通信有哪些方式？
				使用volatile变量保证可见性
				使用synchronized来保证只有一个线程执行方法或者代码块
				等待通知机制：wait和notify、notifyAll
				管道机制：传输媒介是内存。PipedOutputStream、PipedInputStream、PipedReader、PipedWriter
				使用ThreadLocal：主要用于线程隔离
				其他并发工具类：CountDownLatch、CyclicBarrier、Semaphore

			ThreadLocal使用场景：
				存储用户信息
				 	主要用于拦截器中token解析完成之后，将用户信息塞入ThreadLocal变量中，在controller或者service中使用
				数据库连接池：
					能够保证当前线程的所有操作都是用的同一个connection

			父子线程怎么共享数据？
				使用InheritableThreadLocal。
				原理：
					父线程的inheritableThreadLocals不为空，就把它赋值给子线程的inheritableThreadLocals

			Java内存模型：JMM
				原子性：一个操作是不可分割、不可中断，要么全部执行，要么全部不执行。使用synchronized保证
				可见性：一个线程修改了一个变量，其他线程能够立即知道这个修改。使用volatile保证
				有序性：对于单线程来说，从前往后执行，并发时可能会有指令重排。使用synchronized或者volatile都能保证

			线程同步：
				互斥量（mutex)：本质上是一把锁，访问共享变量前先加锁，访问完之后解锁，其他线程阻塞
				读写锁：读模式加锁、写模式加锁和不加锁。写模式加锁只能有一个线程占有，读模式加锁可以有多个线程占有，适用于读多写少的场景
				条件变量：允许线程在满足条件时才继续执行，不满足时等待。与互斥量一起使用，以防止竞争条件的发生。
				自旋锁：锁的一种方式，不会让线程进入睡眠状态，一直循环检测锁是否被释放。自旋锁适用于锁持有时间非常短的情况。
				屏障：
				信号量：本质上是一个计数器。用于为多个线程提供共享数据的访问。

				Java中使用synchronized和Lock进行线程同步
					synchronized是一种互斥量，只能有一个线程获取到资源
					Lock使用最多的是可重入锁ReetrantLock

				synchronized原理：
					代码块：JVM使用monitorenter和monitorexit两个指令实现同步
					同步方法：JVM使用ACC_SYNCHRONIZED标记符来实现同步
					如何实现可见性？
						加锁前：清空工作内存，从主内存中重新加载最新的值
						加锁后：其他线程无法获取主内存中的共享变量
						解锁前：将共享变量的最新值刷回到主内存中
					如何实现有序性？
						自有的排他性，一次只能被一个线程拥有，代码是单线程执行的。
					怎么实现可重入锁？
						锁对象有一个计数器，会记录下线程获取锁的次数，在执行完成之后会进行-1操作，直到清零就释放锁。
					锁升级？Java对象头里面的Mark Word，记录锁的状态。
						无锁状态：没有线程获取锁
						偏向锁：第一个线程执行同步代码块时。目的是消除同一个线程获取和释放锁的开销。对象头记录线程ID
						轻量级锁：多个线程竞争锁，但不是很激烈。线程使用CAS操作对象头的mark word替换为指向锁记录的指针。
						重量级锁：
							多个线程竞争锁，非常激烈。将对象头的mark word
							指向监视器对象来实现，监视器对象里面有锁的持有者，锁的等待队列。

				AQS？并发包的根基。
					ReetrantLock内部使用一个计数器来实现可重入

					CAS：CompareAndSwap，有三个参数，A/B/C，只有A=B时，才将A修改为C。本身能保证原子性
						三大问题：
							ABA问题：
								加版本号解决，AtomicStampReference
							循环性能开销问题：
								设置自旋次数，超过次数，停止自旋
							只能保证一个变量的原子操作：
								用锁来保证操作的原子性；将多个变量封装成对象，使用AtomicReference保证

					多线程下如何保证操作的原子性？
						使用循环原子类，AtomicInteger
						使用juc下的锁，ReetrantLock
						使用synchronized加锁

			线程死锁
				多个线程互相等待对方释放锁资源，导致线程无法执行
				死锁的四个条件：
					互斥条件：每个资源只能被一个线程持有
					持有并等待：一个线程持有了一个资源，且正在等待获取其他资源，这些资源被其他线程占用
					不可剥夺：资源不能被从一个线程中抢占过来，只能由持有资源的线程释放
					循环等待：存在一种循环链
				如何解决？
					互斥条件不能破坏，不可剥夺条件不能被破坏。
					持有并等待：线程在开始之前一次性申请所有的资源
					循环等待：对所有的资源进行排序，强制按照某一个顺序进行申请资源，申请不到时，主动释放自己抢占的资源。
				如何排查？
					系统级别：使用top ps等命令查看线程是否占有过多的资源
					JDK：使用jps -l查看当前的java进程，使用jstack 进程号 查看进程的线程堆栈信息，看是否有线程在等待锁资源
					使用JConsole、VisualVM可视化监控工具来看死锁情况

			并发工具类
				CountDownLatch（倒计数器）：
					协调子线程结束动作，所有线程运行结束之后再一起完成后面的动作
					协调子线程开始动作，统一各线程动作开始的时机
					核心方法：
						await、await（long，TimeUnit）、countdown、getCount

				CyclicBarrier（同步屏障）：循环使用的屏障，相比于CountDownLatch，在于循环使用
					在一组线程到达屏障点时被阻塞，等待最后一个线程到达屏障时，屏障开启，所有线程继续执行

				两者的区别：
					1、CountDownLatch是一次性的，CyclicBarrier是可以循环使用的
					2、CountDownLatch中各个子线程不等待其他线程，只能完成自己的任务；CyclicBarrier中各个线程可以等待其他线程
					3、CountDownLatch面向任务数，CyclicBarrier面向线程数

				Semaphore（信号量）
					用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源。
					用处：流量控制。比如数据库连接

			线程池
				线程池参数：
					核心线程数：线程核心参数选择了 CPU 数 ×2
					最大线程数：最大线程数选择了和核心线程数相同
					存活时间：非核心闲置线程存活时间直接置为 0
					存活时间单位：TimeUnit.SECONDS
					线程工厂
					阻塞队列：使用LinkedBlockingQueue实现阻塞队列
						ArrayBlockingQueue：数组实现的有界队列
						LinkedBlockingQueue：链表结构实现的队列
						DelayQueue：延迟队列
						PriorityBlockingQueue：有优先级无界阻塞队列
						SynchronousQueue：无元素存储阻塞队列
					拒绝策略
						直接丢弃，抛出异常
						直接丢弃任务，不抛出异常
						用调用者的线程执行任务
						丢弃最旧的任务
						
				线程池关闭：shutdown、shutdownNow
					原理：遍历线程池中的工作线程，依次调用interrupt方法来中断线程
					shutdown：
						1、线程池状态设置为shutdown，不会立即停止
						2、停止接收新的任务
						3、等待线程正在执行的任务和任务队列中的任务完成
						4、停止线程池
					shutdownNow：
						1、线程池状态设置为stop，一般不会立即停止，事实上不一定
						2、停止接收新的任务
						3、忽略队列里的等待任务
						4、尝试调用正在执行任务的线程的interrupt方法
						5、返回未执行的任务列表
				线程数怎么配置？
					计算密集型：核心线程数=CPU核数+1
					IO密集型：核心线程数=CPU核数*2
					混合型：可视情况配置为计算密集型或者IO密集型
					具体可以结合测试和监控进行调整
				有哪几种线程池？
					newFixedThreadPool：固定线程数的线程池。
						使用LinkedBlockingQueue无界队列，可能会OOM
					newCachedThreadPool：可缓存线程的线程池。核心线程为0，
						最大线程为Int最大值，可能会OOM，使用SynchronousQueue队列
					newSingleThreadExecuter：单线程的线程池。
						使用LinkedBlockingQueue无界队列，可能会OOM
					newScheduleThreadPool：定时及周期执行的线程池
						最大线程为Int最大值，可能会OOM，使用DelayedWorkQueue
				线程池调优
					上线前测试，上线后建立线程池监控，配合监控报警机制
					事前评估 -> 监控/告警 -> 动态调整 -> 事后观察

		JVM
			1、类加载器
				从文件系统、网络或者其他来源加载class文件，将class文件中的二进制数据加载到内存中

				类加载机制三个重要概念：
					类加载器
						加载class文件到内存中，生成class对象

					类加载过程
						加载、验证、准备、解析、初始化

					双亲委派模型
						自己先不加载，把请求委派给父类加载器去加载，依次递归，直到最顶层的类加载器，如果父类加载器无法加载类，子类加载器才会去尝试自己加载

						为什么要这么做？
							保证Java核心类库的类型安全
							避免类的重复加载

				类生命周期：
					加载 - 验证 - 准备 - 解析 - 初始化 - 使用 - 卸载

				类加载器有哪些？
					启动类加载器（Bootstrap ClassLoader)
					扩展类加载器（Extension ClassLoader）
					应用程序类加载器（Application ClassLoader）
					用户自定义类加载器（User-Defined ClassLoader)


			2、运行时数据区
				线程私有：虚拟机栈、本地方法栈、程序计数器
				线程公有：堆、元空间（方法区）

				对象怎么进行访问定位？
					Java程序会通过栈上的Reference数据操作堆上的具体对象。
					使用句柄访问：
					直接指针访问：

				堆内存分区：
					新生代：Eden、from、to = 8 ：1 ：1
					老年代

			3、执行引擎
				执行字节码，包括虚拟处理器，还包括即时编译器（JIT Compiler）和垃圾收集器（GC）

				垃圾判断算法？
					引用计数算法：对象头中记录对象被引用的次数
					可达性分析算法：通过一些引用链的对象作为起点，向下搜索，当一个对象到GC Roots之间没有任何引用时，即从GC Roots到当前对象不可达时，说明此对象是垃圾，可以被回收

					GC Roots有哪些？
						虚拟机栈中引用的对象
						本地方法栈中引用的对象
						方法区种静态属性引用的对象
						方法区中常量引用的对象
						被同步锁synchronized持有的对象
						基本数据类型的class对象、异常对象
						JMXBean、JVMTI中注册的回调、本地代码的缓存


				垃圾回收算法有哪些？
					标记-清除算法
					复制算法
					标记-整理算法
					组合算法：分代收集算法，新生代使用复制算法，老年代使用标记-清除算法或者标记-整理算法

				垃圾收集器有哪些？
					Serial：单线程
					ParNew：多线程垃圾回收
					ParallelScanvenge：关注吞吐量，基于标记-复制算法，能够并行收集
					SerialOld：Serial的老年代版本
					ParallelOld：ParallelScanvenge的老年代版本，支持多线程并发收集，基于标记-整理算法实现
					CMS：第一个关注停顿时间的垃圾收集器。基于标记-清除算法实现
						初始标记-并发标记-重新标记-并发清除
						初始标记是单线程标记，需要STW
						并发标记是多线程并发标记，无需STW
						重新标记是多线程并发标记，需要STW
						并发清除无停顿，和用户线程同时执行，无需STW

					G1：分Region进行回收，先回收回收价值最高的Region
						把堆分成多个大小相等的Region，每个Region可以扮演新生代或老年代的角色，还单独为大对象定义了大对象的
						Region
						四个阶段：
							初始标记-并发标记-重新标记-筛选回收
						三个好处：
							1、并发标记，不会STW
							2、筛选回收阶段，会优先回收回收价值大的Region，提高回收效率，减少停顿时间
							3、可预测的停顿，增加预测机制，用户可以在JVM启动时指定期望的停顿时间，G1会尽可能在这个时间内完成

						G1相比于CMS，主要是解决CMS内存碎片过多的问题

					ZGC：低延迟垃圾收集器，适用于大内存低延迟服务的内存管理和回收
						基于指针染色和读屏障

					你们线上使用的是什么垃圾收集器？
						我们比较关注服务的响应速度，所以选用ParNew+CMS收集器
						CMSInitiatingOccupancyFraction：设定超过75时进行老年代垃圾回收，尽可能平衡回收次数和停顿时间
						CMSFullGCBeforeCompaction：解决内存碎片过多的问题，在一定次数的FullGC之后进行整理

				GC的几个概念：
					部分收集：
						新生代收集：MinorGC/YoungGC
						老年代收集：MajorGC/OldGC，只有CMS有单独的老年代收集行为
						混合收集：MixedGC，收集整个新生代和部分老年代的垃圾收集，只有G1会有

					整堆收集：FullGC
						整个Java堆和方法区的收集

				有做过JVM调优的工作吗？
					在晚上高峰时期，通过监控发现MajorGC次数比较比平时多一倍的情况。
					去观察监控和GC日志分析，由于业务创建一些大对象导致GC频繁，首先想到的是JVM调优。首先调整了CMSInitiatingOccupancyFraction参数，从原来的60%调整到75%，使MajorGC次数明显减少，同时停顿时间没有太大变化。后续做了业务方向的优化。

				内存飙升的情况有遇到过吗？
					有一天晚上突然服务一个容器重启，然后每过一段时间就会容器重启的报警。监控上看到的情况就是内存耗尽。
					通过监控观察到句柄相关的内存增长很快，通过句柄以及对堆内存文件进行分析，定位到由于没有使用到kafka连接池导致每次请求都创建一个连接，从而导致的句柄快速增加，从而导致的内存的快速增长，通过修复代码重新上线解决此问题


	2、Spring相关

		Bean 的生命周期
			实例化  new
			属性赋值   setter 
			初始化    
				检查Aware接口
				BeanPostProcessor前置处理
				是否实现InitializingBean接口
				是否配置init-method方法
				BeanPostProcessor后置处理 
			销毁
				是否实现DisposableBean接口
				是否配置destroy-method方法

		依赖注入的方式
			构造方法注入
			setter属性注入
			工厂方法注入

		Spring 中的单例 Bean 会存在线程安全问题吗？会
			如何解决？
				定义bean为原型prototype
				定义bean的变量为不可变变量
				成员变量使用threadlocal进行存储

		循环依赖？A依赖B，B依赖A或者C依赖C
			Spring可以解决哪些情况的循环依赖？
				都使用setter方法注入
				都使用属性注入
				一个bean使用setter方法注入，一个bean使用构造方法注入（可能可以，取决于创建bean的顺序）
			
			如何解决？单例bean初始化三步：实例化-属性赋值-初始化
				构造三级缓存：	
					一级缓存：singletonObjects 三步全部完成的bean
					二级缓存：earlySingletonObjects 实例化完成的bean
					三级缓存：singletonFactories bean的创建工厂，以便后面创建bean的代理对象
				为什么不用两级缓存？
					主要是为了生成代理对象
				步骤：
					1、A实例化，把A的创建工厂放入三级缓存
					2、A属性赋值时依赖B，去实例化B
					3、B属性注入时发现依赖A，去缓存里面找A，从一级到三级缓存依次找。从三级缓存找到A，删除三级缓存中的A，把A放入二级缓存，B初始化完成，放入一级缓存
					4、对A进行属性赋值，从一级缓存中找到B，A初始化完成，删除二级缓存中的A，放入一级缓存
					5、最后一级缓存中保存着实例化初始化都完成的A和B
				原理：实例化和属性赋值时分开的，有操作的空间，如果都使用构造器注入就需要在实例化阶段完成，就没有操作空间了

		AOP的原理，作用
			原理：动态代理（可以使用JDK动态代理，也可以使用CGLIB动态代理）
			作用：提高代码的可重用性，具体的：参数校验，记录日志，事物管理，安全检查，缓存
			核心概念：切面，连接点，通知，切点，引入，织入
			通知类型：前置通知，后置通知，环绕通知，异常通知，返回通知

		Spring事物
			种类：
				编程式事务：TransactionTemplate/PlatformTransactionManager
				声明式事务: @Transactional 核心是AOP
			隔离级别：脏读、不可重复读、幻读
				DEFAULT：MySQL默认可重复读，Oracle读已提交
				READ_UNCOMMITTED: 读未提交
				READ_COMMITTED: 读已提交
				REPEATABLE_READ: 可重复读
				SERIAL: 串行化
			传播机制：方法被另外一个事务执行时，这个方法的事务行为。内部使用ThreadLocal实现，所以只在一个线程中生效
				REQUIRED：如果当前存在事务，加入该事务；不存在事务，开启新的事务。默认传播机制
				SUPPORTS：如果当前存在事务，加入该事务；不存在事务，以非事务方式运行
				MANDATORY：如果当前存在事务，加入该事务；不存在事务，抛出异常
				REQUIRED_NEW：总是启动一个新的事务，如果当前存在事务，则将当前事务挂起
				NOT_SUPPORTED：总是以非事务方式运行，如果当前存在事务，则将当前事务挂起
				NESTED：如果当前存在事务，则在嵌套事务内运行；如果当前不存在事务，开启新的事务。依赖于父事务的运行，父事务失败，当前事务失败回滚；子事务失败不一定会导致父事务回滚
				NEVER：不使用事务
			失效：
				1、protected、private方法上的注解。原因是动态代理只会针对于public方法做增强
				2、同一个方法内的内部调用时，如果内部调用使用了注解，注解失效。原因也是动态代理，动态代理会生成类的代理对象，代理对象只会在外部方法中检测注解，如果没有注解则不会进行动态代理会直接调用
				3、传播机制设置错误
				4、rollbackFor设置错误

		MVC：
			流程：
				客户端请求
				  ｜
				DispatcherServlet - HandlerMapping - HandlerAdapter - Controller - ModelAndView - View解析
				  ｜ 
				客户端响应

		Sprintboot启动流程
			new SpringApplication 初始化
				判断是否是web环境
				获取所有的初始化器
				获取所有的监听器
				确定main方法

			run 真正开始执行
				headless系统属性配置
				初始化监听器并启动监听
				配置环境Environment
				打印banner
				创建IoC容器
				配置IoC容器的基本信息（前置处理）
				刷新容器
				刷新容器后置处理
				发布应用启动完成

		SpringBoot自动装配原理
			容器利用反射技术，根据bean的类型、名称等自动注入所需的依赖。
			1、开启自动装配的注解@EnableAutoConfiguration，核心是AutoConfigurationImportSelector，
			2、其实现了ImportSelector接口，收集需要导入的配置类，配合@Import注解将相应的类导入到Spring容器中
			3、获取注入类的方法是selectImports方法，实际调用的是getAutoConfigurationEntry获取自动装配类
			自动装配原理依赖于Spring框架的依赖注入和条件注册，通过这种方式Spring可以智能地装配Bean，并且只有这些bean实际需要时才会创建和配置。

		有解决过Spring相关的问题？
			zk导致的容器重启问题
			直接原因是k8s的健康检查无法探活，所以对容器进行了重启调度
			原因定位：
				1、通过日志进行定位由于HikariDatasource无法重建bean导致健康检查不通过
				2、通过发生时间和HikariDatasource配置变动推测是由于配置改动导致
				3、在测试环境实验测试可以通过修改zk配置稳定复现
			解决思路：
				1、不让配置修改影响HikariDataSoure，这个思路被spring cloud官方采纳，升级SpringCloud Hoxton.SR3
				2、升级SpringCloud、SpringBoot、Spring到对应版本

		常用的限流算法：
			窗口算法：固定窗口算法、滑动窗口算法
			桶算法：漏桶算法、令牌桶算法

			本地限流组建：Guava RateLimit、Redis+lua
			中间件：sentinel


	3、MySQL （小林coding 图解MySQL）https://xiaolincoding.com/mysql
		B+树和B树有什么区别：
			B+树其叶子节点是存储的数据，B树在非叶子节点上也要存储数据，这样的话B+树中间节点数据量小，就能存放更多的数据，也就能减少IO操作
			B+树叶子节点之间采用双向链表连接，可以快速进行顺序范围查找。B树则不能。

		B+树像相比于二叉树的区别：
			B+树是多路索引树，对于千万级的数据，只需要3-4次IO操作就能查询到对应的数据，查询效率高
			二叉树时间复杂度是O(logN)

			与红黑树的区别：
				首先从高度上，相同数据量的话，红黑树是二叉查找树，高度更高，不利于查询，更有利于排序
				其次需要维护红黑树的话，需要进行染色和旋转操作，耗费性能


		主键索引和二级索引的区别：
			主键索引叶子节点上存储的是真实数据，二级索引叶子节点上存储的是主键值，如果需要查询除主键外的其他字段，需要进行回表操作

		一条SQL的执行顺序：
			FROM -> ON -> JOIN -> WHERE -> GROUP -> HAVING -> SELECT -> DISTINCT -> ORDER BY -> LIMIT

		in和exist的区别
			in是将内外表使用hash连接，exist是对外表做loop循环，然后遍历内表查询。
			区分场景看效率：
				1、内外表一样大，in和exist区别不大
				2、子查询表大的使用exist，子查询表小的使用in
				3、not in不会使用索引，所以全表扫描，not exist仍然能使用索引，所以not exist效率会高一些

		count(1) count(*) count(列名)的区别和执行速度
			count(1)不会忽略列为null的情况
			count(*)不会忽略列为null的情况
			count(列名)会忽略列为null的情况
			执行速度：
				count(主键) > count(1) > count(索引列) > count(*)

		一条SQL查询语句在MySQL中是如何执行的？
			1、首先检查该语句是否有权限，如果没有，直接返回错误；如果有，查询缓存
			2、如果没有缓存，分析器进行语法分析，判断SQL是否有语法错误
			3、如果没有语法错误，优化器会对SQL进行优化，确定执行方案
			4、按照执行计划调用搜索引擎进行查询，返回执行结果

		InnoDB和MyISAM的区别？
			事务：InnoDB支持，MyISAM不支持
			锁粒度：InnoDB支持表级锁和行级锁，MyISAM只支持表级锁
			索引类型：InnoDB为聚簇索引，数据存储在索引上；MyISAM为非聚簇索引，索引和真实数据分开存储
			外键支持：InnoDB支持外键，MyISAM不支持
			表的具体行数：MyISAM直接存储了表的行数，不用重新统计；InnoDB需要扫描表统计返回
			主键必须：MyISAM可以没有主键，InnoDB必须要有主键

		binlog：
			1、主从复制
			2、数据恢复（包括全量binlog和增量binlog）
		两阶段提交：binlog和redolog

		如何进行分页优化？
			1、延迟关联：先对一个表进行分页，然后再去关联其他表进行JOIN操作
			2、书签：记录下上一页最后一行的值，根据这个值进行分页查询，避免扫描大量不需要的行

		如何进行索引优化？
			1、使用覆盖索引：避免回表
			2、避免使用!=或者<>操作符：索引失效，导致全表扫描
			3、适当使用前缀索引：注意无法使用前缀索引进行order by和group by操作
			4、避免列上使用函数：索引失效
			5、正确使用联合索引

		执行计划：explain
			id、select_type、table、type、possible_keys、keys、key_len、ref、rows、extra
			重点关注type：
				system>const>eq_ref>ref>fulltext>ref_or_null>index_merge>unique_subquery>index_subquery>range>index>all
			possible_keys：可能使用到的索引
			keys：实际使用到的索引
			ref：与索引列做等值匹配的值
			rows：估算SQL需要扫描的行数
			extra：
				using index：使用覆盖索引，避免回表
				using where：会在存储引擎检索之后再进行过滤
				using temporary：对查询结果集排序时会使用到临时表
				file sort：文件排序

		索引失效的情况：
			1、使用函数
			2、使用!=或者not
			3、使用like前面加%
			4、使用or
			5、联合索引不满足最左前缀原则

		覆盖索引：
			在辅助索引里面，如果select的数据直接从辅助索引中就可以取得，不用回主键索引中查询，这时候辅助索引就叫覆盖索引，避免了回表

		索引下推优化：
			在条件查询时，MySQL server层将过滤条件下推给引擎层，
			由引擎层进行条件过滤，减少回表的次数，也可以减少server层从引擎层接收数据的次数
			extra里面有using index condition

		MySQL的锁
			记录锁RecordLock
			间隙锁GapLock：解决幻读的问题
			临键锁NextKeyLock：解决幻读的问题

			死锁问题如何解决：
				查看死锁日志，show engine innodb status; 找到死锁的sql，分析模拟加锁顺序

		ACID靠什么保证？
			A原子性：undo log，使用undo log进行事务回滚操作
			C一致性：保证了原子性、隔离性、持久性就自然保证了一致性
			I隔离性：使用MVCC机制或锁机制来处理并发事务，使用快照读的方式
			D持久性：使用redo log来保证持久性，InnoDB先写入redo log，这种方式被称为WAL（Write-ahead log先写日志）

			事务的隔离级别：
				读未提交：事务读不加锁，不阻塞其他事务的读和写
				读已提交：使用MVCC + ReadView，每次读取前都生成一个ReadView
				可重复读：使用MVCC + ReadView，在启动事务时生成一个ReadView
				串行化：读和写都加锁

			如何实现可重复读？
				聚簇索引的两个隐藏列：
					trx_id/roll_pointer(连接undo log)

				ReadView的几个重要字段：
					creator_trx_id：创建该ReadView的事务ID
					m_ids：活跃的事务ID列表，活跃指启动了还没提交
					min_trx_id：活跃事务中事务ID最小的事务
					max_trx_id：创建ReadView时应该分配的下一个事务ID

				B读取记录，A修改记录，B再读取记录

				A开启一个ReadView，B也开始一个ReadView，当trx_id小于min_trx_id时，说明记录当前值是可见的，B读到了100
				A修改后提交，会把之前的记录放在undo log中，使用roll_pointer进行连接
				B再次读取时，因为ReadView没变，trx_id变大，同时存在于m_ids中，所以通过版本链即undo log查找找到上一次的记录，读取值为100

			锁：
				意向锁的目的是为了快速判断表里是否有记录被加锁。

				表级锁：
					意向锁

				行级锁：
					记录锁
					间隙锁
					nextkey lock

					普通读不会进行加锁，属于快照读；只有手动设置lock in share mode 或者for update才会加锁


		主从复制：binlog


		分库分表分别适用于什么场景？
			分库：解决容量和连接数的问题
				垂直分库：不同业务的表分布在不同的库中
				水平分库：按照一个的分库策略将一个表的不同数据拆分到多个库中
			分表：解决单表查询性能的问题
				解决单表数据存储压力和查询压力

			分库分表常用中间件：
				sharding-jdbc
				mycat

			带来的问题：
				事务的问题：不能使用单机事务，必须使用分布式事务
				跨库JOIN问题：使用业务代码进行关联
				ID问题：分布式ID

		分布式事务：
			TCC事务： Try Confirm Cancel
			SAGA事务

	4、Redis （小林coding 图解Redis）https://xiaolincoding.com/redis
		redis使用几种类型的使用场景：
			1、string：普通缓存、分布式锁、计数、共享session
			2、hash：缓存对象信息、缓存用户信息
			3、list：消息队列，各种列表（用户列表、点赞列表、文章列表）
			4、set：标签、共同关注
			5、zset：用户点赞统计、用户排序、各种排行榜

		线程模型：
			redis快的原因？
				1、基于内存的数据存储（根本原因）
				2、单线程模型，执行命令的线程是单线程，避免线程切换和锁竞争带来的消耗
				3、IO多路复用，基于Linux的select/epoll机制，redis一个线程监听多个套接字处理。
				4、高效的数据结构，这些数据结构高度优化，能够支持快速的数据访问

			具体解释一下IO多路复用？
				一个线程监听多个套接字，有一个套接字上有消息到达就处理哪个请求，收发消息不会发生阻塞，基于事件驱动，所谓的reactor模式

			redis为什么选择单线程？
				redis是执行命令的线程是单线程操作，其他还有三个线程执行其他任务，写入文件、异步清理过期键、网络读写操作
				1、redis是基于内存进行操作的，CPU不是其瓶颈点，而内存和网络是其瓶颈点。
				2、如果是多线程的情况下，要进行线程切换和锁的竞争。

		持久化方式有哪些？
			RDB 和 AOF
			RDB：save命令和bgsave命令，使用快照的方式进行持久化
				优点：
					1、只有一个文件，适合全量备份的场景
					2、容灾性好，适合拷贝后快速容灾恢复
					3、恢复速度快
				缺点：
					1、实时性低，间隔一段时间进行生成，最近一段时间的数据缺失
					2、存在兼容问题，格式变化，新老版本可能不兼容
			AOF：写操作命令同步到日志中，写命令首先append到AOF缓冲区，AOF缓冲区再刷新到AOF文件中
				刷新到AOF文件的几个策略：always、everysec、no
				优点：
					1、实时性好
					2、通过append模式写文件，即使中途宕机，也可以通过redis-check-aof工具解决数据一致性的问题
				缺点：
					1、文件比较大，恢复速度慢
					2、数据集大的时候，比RDB启动效率低

			如何选择？
				一般选择混合持久化的方式，即前面是RDB数据信息，后面是AOF命令信息在一个文件中

		高可用：
			主从结构：
				主从数据同步的方式：全量复制和部分复制
			哨兵模式：
				解决主从结构下自动故障转移问题
			Redis集群
				16384个槽，每个槽分布在不同的集群节点上，每个节点管理一部分槽，每个节点都可以承担读写功能

		缓存设计
			缓存击穿、缓存穿透、缓存雪崩
				缓存击穿：一个或几个热点key过期，导致大量请求打到数据库上
					解决方法：
						1、加锁，读数据库然后放入缓存中，其他请求直接在缓存中读取
						2、不让key过期，异步刷新key
				缓存穿透：请求的key不在缓存中，导致请求打到数据库上
					原因分析：
						1、自身代码逻辑问题
						2、恶意攻击或者是爬虫
					解决方法：
						1、缓存空值或者固定值
							存在的问题：
								缓存的key过多，占用空间（加一个短的过期时间）
								缓存的数据和实际数据会不一致，影响业务
						2、使用布隆过滤器
				缓存雪崩：某一个时间点，大量的缓存数据同时过期或者redis崩溃，导致所有的请求打到数据库上
					解决方法：
						1、使用redis集群，降低redis服务崩溃的风险
						2、设置不同的过期时间，尽量打散过期时间（固定值+随机值）
						3、业务侧：限流或者降级保护服务和数据库

			如何保证缓存一致性？
				先更新数据库再删缓存
					为什么要这么做？
						因为数据库操作比较耗时，如果先删缓存，在数据库更新前另外一个请求读到数据库的旧值重新更新到redis缓存

				如果要保证强一致性，如何解决？
					1、引入消息队列保证缓存被删除，保证最终一致性
					2、数据库订阅（Canal监听binlog）+ 消息队列保证缓存被删除
					3、延迟双删
					4、设置缓存时间兜底

			如何保证本地缓存和redis的数据一致性？
				1、使用redis的发布订阅机制，订阅到删除消息后进行本地缓存的删除
				2、引入消息队列
				3、设置适当的过期时间，本地缓存的过期时间要小于redis的过期时间

			怎么处理热key？
				1、热点key打散，通过加前缀后者后缀的方式打散到不同的机器上，降低单个机器的压力
				2、加入本地缓存，命中后直接从本地缓存读取，避免打到redis上

			内存淘汰策略
				noeviction：默认策略，对写操作返回错误
				volatile-lru：设置了过期时间的键中使用lru算法淘汰数据
				allkeys-lru：对所有键使用lru算法淘汰数据
				volatile-random：对设置了过期时间的键随机淘汰数据
				allkeys-random：对所有键随机淘汰数据
				volatile-ttl：从所有设置了过期时间的键中挑选ttl最短的键进行淘汰
				volatile-lfu：对所有设置了过期时间的键使用lfu算法淘汰数据
				allkeys-lfu：对所有键使用lfu算法淘汰数据

			大key的问题如何解决？
				删除大key：
					1、使用unlink就可以使用后台线程去删除大key，避免阻塞主线程
					2、使用scan增量迭代扫描大key，然后进行删除
				压缩和拆分大key：
					1、对于value使用更高的压缩算法
					2、拆分，将一个对象拆成多个key存储，使用multiget获取全部数据
					3、



		锁、锁超时时间、锁续期
		线程模型
		多路复用原理

	5、Kafka（https://javabetter.cn/interview/kafka-40.html）
		使用场景：
			日志聚合、流量削峰、系统解耦、消息系统、异步处理

		rebalance 消费者组内
			增加consumer
			减少consumer

		topic、partition、 consumer、 consumer group、 offset

		如何指定分区消费消息
			fetch
			seek(topicPartition)

		ACK机制
			0：发送完不管kafka是否接收
			1：发送完leader确认接收
			-1、all：发送完所有副本确认接收
			2：发送完部分副本确认接收

		consumer是如何消费数据的？
			pull的过程

		日志保留期和数据清理策略
			默认固定保留7天，可以修改
			清理策略：
				删除：先标记为删除状态，然后过一段时间后才真正删除
				压缩：只保留每个key最后一个版本的数据

		日志分段策略和刷新策略
			分段策略：
				滚动周期，到达一个周期生成一个segment，默认7天
				每个segment最大容量，超过重新生成一个，默认1GB
				日志片段文件检查周期，默认60s
			刷新策略：从缓存刷到日志文件
				达到多少条刷一次，默认是10000
				到达多长时间刷一次，默认为null
				周期性检查，默认为很大的值

		消息丢失、数据不一致的情况
			发送：ACK 
				极致安全性使用-1
				重试
			消费：拉取消息后直接提交offset，然后消费者挂了
				关闭自动提交offset，改为手动提交offset
				重复消费问题：业务侧幂等验证 、 建立去重表

		如何保证顺序消费
			Partition内部是可以保持顺序性的，所以我们在发送消息时要控制将保证顺序性的消息发往同一个partition
			使用API可以指定topic的partition进行发送

		和其他MQ对比
			极致的性能，内部使用批量处理和异步的思想，最高可以每秒处理千万级的数据
			生态系统兼容性无可匹敌：在大数据和流处理领域，与周边生态兼容性好

	6、计算机系统和网络

		http 1.0 1.1 2.0 3.0的区别
			1.0：无状态、无连接，使用短链接实现
			1.1：支持长链接，支持断点续传
			2.0：header压缩；使用多路复用技术，支撑更大的并发请求；支持服务器推送
			3.0：基于UDP协议和应用层实现TCP协议。解决了线头阻塞的问题，在切换网络时能保持连接

		长链接和短链接的区别
			短链接：每次通信结束后断开连接，下次通信时重新建立连接。耗时且浪费资源。
			长链接：通信结束后维持一段时间。

			使用场景：在web端一般使用短链接，长链接耗费资源过多。在数据库连接池一般使用长链接，减少创建连接的时间和资源的消耗。

	7、Linux
		操作字符串的几个命令：
			awk：输出匹配到的格式的数据
			sed：操作字符串，可以增加删除行
			cut：操作文件，输出指定行
			wc：统计字符串出现的次数
			printf：输出匹配的字符









